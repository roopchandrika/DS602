{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 - PCA and Dimension Reduction Homework\n",
    "Execute the below code and answer the following questions. __Do NOT commit the csv file!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def generate_data():\n",
    "    x, y = make_classification(n_samples=1500, \n",
    "                            n_features = 20,\n",
    "                            n_informative = 8,\n",
    "                            n_redundant = 5,\n",
    "                            n_repeated = 1, \n",
    "                            n_classes = 3,\n",
    "                            weights = (0.5, 0.25, 0.25),\n",
    "                            random_state = 120\n",
    "                            )\n",
    "    colNames = ['var'+str(x) for x in range(20)]\n",
    "    colNames.append('target')\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate((x,y.reshape(-1,1)), axis=1), columns=colNames)\n",
    "    df.to_csv('pca-dataset.csv', index=False)\n",
    "    \n",
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var0</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.882513</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-2.520732</td>\n",
       "      <td>-1.987174</td>\n",
       "      <td>-2.073689</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-1.237969</td>\n",
       "      <td>1.690547</td>\n",
       "      <td>-0.211314</td>\n",
       "      <td>-5.753190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574979</td>\n",
       "      <td>-1.916275</td>\n",
       "      <td>-5.994075</td>\n",
       "      <td>-3.349615</td>\n",
       "      <td>-0.846193</td>\n",
       "      <td>2.491347</td>\n",
       "      <td>1.360958</td>\n",
       "      <td>-2.892522</td>\n",
       "      <td>-1.377561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775242</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.590205</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>1.350954</td>\n",
       "      <td>-1.493037</td>\n",
       "      <td>-0.862391</td>\n",
       "      <td>-1.986047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523760</td>\n",
       "      <td>0.399579</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.718606</td>\n",
       "      <td>-1.112030</td>\n",
       "      <td>0.083929</td>\n",
       "      <td>0.606544</td>\n",
       "      <td>-1.376793</td>\n",
       "      <td>1.302641</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.876376</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>3.114224</td>\n",
       "      <td>-1.640025</td>\n",
       "      <td>1.180348</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>0.465102</td>\n",
       "      <td>0.222511</td>\n",
       "      <td>0.880455</td>\n",
       "      <td>2.922315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370516</td>\n",
       "      <td>3.585262</td>\n",
       "      <td>-2.168162</td>\n",
       "      <td>2.693429</td>\n",
       "      <td>-0.966636</td>\n",
       "      <td>1.586302</td>\n",
       "      <td>-2.821546</td>\n",
       "      <td>0.482164</td>\n",
       "      <td>0.187404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.550342</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>0.077681</td>\n",
       "      <td>-1.887719</td>\n",
       "      <td>1.864445</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>-0.527958</td>\n",
       "      <td>-0.201467</td>\n",
       "      <td>-0.532649</td>\n",
       "      <td>2.287445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041341</td>\n",
       "      <td>2.383582</td>\n",
       "      <td>-0.417253</td>\n",
       "      <td>1.305379</td>\n",
       "      <td>-0.435123</td>\n",
       "      <td>-0.468557</td>\n",
       "      <td>0.923290</td>\n",
       "      <td>3.880050</td>\n",
       "      <td>2.676798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.454974</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.112201</td>\n",
       "      <td>-0.589989</td>\n",
       "      <td>-1.674321</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.487302</td>\n",
       "      <td>1.776318</td>\n",
       "      <td>0.702520</td>\n",
       "      <td>-1.024127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452869</td>\n",
       "      <td>-0.667306</td>\n",
       "      <td>0.345364</td>\n",
       "      <td>-3.920591</td>\n",
       "      <td>-0.438296</td>\n",
       "      <td>-1.690141</td>\n",
       "      <td>0.176906</td>\n",
       "      <td>1.920142</td>\n",
       "      <td>1.474634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var0      var1      var2      var3      var4      var5      var6  \\\n",
       "0 -2.882513 -3.272465 -2.520732 -1.987174 -2.073689 -3.272465 -1.237969   \n",
       "1  0.775242 -1.015994  0.005137  0.057274  0.590205 -1.015994  1.350954   \n",
       "2 -0.876376  0.220453  3.114224 -1.640025  1.180348  0.220453  0.465102   \n",
       "3 -2.550342 -1.968144  0.077681 -1.887719  1.864445 -1.968144 -0.527958   \n",
       "4 -0.454974  1.293300  0.112201 -0.589989 -1.674321  1.293300  0.487302   \n",
       "\n",
       "       var7      var8      var9  ...     var11     var12     var13     var14  \\\n",
       "0  1.690547 -0.211314 -5.753190  ... -0.574979 -1.916275 -5.994075 -3.349615   \n",
       "1 -1.493037 -0.862391 -1.986047  ...  0.523760  0.399579  0.088600  0.718606   \n",
       "2  0.222511  0.880455  2.922315  ... -0.370516  3.585262 -2.168162  2.693429   \n",
       "3 -0.201467 -0.532649  2.287445  ... -0.041341  2.383582 -0.417253  1.305379   \n",
       "4  1.776318  0.702520 -1.024127  ... -0.452869 -0.667306  0.345364 -3.920591   \n",
       "\n",
       "      var15     var16     var17     var18     var19  target  \n",
       "0 -0.846193  2.491347  1.360958 -2.892522 -1.377561     0.0  \n",
       "1 -1.112030  0.083929  0.606544 -1.376793  1.302641     2.0  \n",
       "2 -0.966636  1.586302 -2.821546  0.482164  0.187404     0.0  \n",
       "3 -0.435123 -0.468557  0.923290  3.880050  2.676798     1.0  \n",
       "4 -0.438296 -1.690141  0.176906  1.920142  1.474634     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pca-dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   var0    1500 non-null   float64\n",
      " 1   var1    1500 non-null   float64\n",
      " 2   var2    1500 non-null   float64\n",
      " 3   var3    1500 non-null   float64\n",
      " 4   var4    1500 non-null   float64\n",
      " 5   var5    1500 non-null   float64\n",
      " 6   var6    1500 non-null   float64\n",
      " 7   var7    1500 non-null   float64\n",
      " 8   var8    1500 non-null   float64\n",
      " 9   var9    1500 non-null   float64\n",
      " 10  var10   1500 non-null   float64\n",
      " 11  var11   1500 non-null   float64\n",
      " 12  var12   1500 non-null   float64\n",
      " 13  var13   1500 non-null   float64\n",
      " 14  var14   1500 non-null   float64\n",
      " 15  var15   1500 non-null   float64\n",
      " 16  var16   1500 non-null   float64\n",
      " 17  var17   1500 non-null   float64\n",
      " 18  var18   1500 non-null   float64\n",
      " 19  var19   1500 non-null   float64\n",
      " 20  target  1500 non-null   float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 246.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1,200\n",
      "Test samples: 300\n",
      "\n",
      "Features:\n",
      "var0\tvar1\tvar2\tvar3\tvar4\tvar5\tvar6\tvar7\tvar8\tvar9\tvar10\tvar11\tvar12\tvar13\tvar14\tvar15\tvar16\tvar17\tvar18\tvar19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[x for x in df.columns if x.startswith('var')]]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_training, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]:,}')\n",
    "print(f'Test samples: {X_test.shape[0]:,}')\n",
    "\n",
    "print('\\nFeatures:')\n",
    "print(*X_train, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "- `var1 - var19`: a feature for the data.  \n",
    "- `target`: variable we wish to be able to predict, which is 1 of 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Use principle components analysis to determine the number of components to reduce the data to by evaluating the explained variance ratio (use `X_train`).  \n",
    "- Remember to scale the data first.  \n",
    "- What number of components would you recommend based on your analysis?  \n",
    "- Explain your results using markdown cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing pca to determine number of components\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.78248763e-01, 1.31423463e-01, 1.03428992e-01, 8.93001375e-02,\n",
       "       7.00271587e-02, 6.26207004e-02, 5.53463463e-02, 5.16479599e-02,\n",
       "       4.98606225e-02, 4.86667259e-02, 4.67744196e-02, 4.42653499e-02,\n",
       "       4.16638974e-02, 2.67254645e-02, 4.89685831e-33, 3.16068688e-33,\n",
       "       2.25237610e-33, 1.99911215e-33, 1.58621238e-33, 3.26439474e-34])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cum_var_exp = np.cumsum(explained_variance_ratio)\n",
    "plt.bar(range(1,21), explained_variance_ratio, alpha=0.5, align='center', label='Variance Explained')\n",
    "plt.step(range(1,21), cum_var_exp, where='mid', label='Cumulative Explained')\n",
    "plt.xlabel('Principal Componment')\n",
    "plt.ylabel('Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Describe your results here\n",
    "\n",
    "**In the above cells I have done the following:-**\n",
    "- I have done the standard scaling for features both for training and testing dataset.\n",
    "- Then, I have implemented PCA to determine number of components.\n",
    "- After which, I have found the explained variance ratio for the PCA. When this value is higher, it indicates that it is a more informative content and cumulative sum of this determines number of components to be used for dimensionality reduction.\n",
    "- Then, I have plotted the cumulative sum of explained variance ratio to determine number of components which can be found by taking the point where the elbow of the curve stops increasing. Here, in the above plot stops increasing when number of components is approximately 14. So, I can say that 14 components are required for dimensionality reduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- Evaluate the target variable in the `df` object.  \n",
    "- Which metric would you use in evaluating a predictive model. Explain your choice in the markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    744\n",
       "2.0    380\n",
       "1.0    376\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the target column distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='target', data=df)\n",
    "plt.title('Target column distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Describe your results here\n",
    "\n",
    "**In the above cells, I have done the following:-**\n",
    "- I have got the value counts of target column, 0.0 with 744, 2.0 wit 380 and 1.0 with 376 which means the target column is unbalanced. It is multi-class column.\n",
    "- I have also plotted the target column distribution using countplot. 1.0 and 2.0 have same value distribution whereas 3.0 has the distribution double of 1.0 and 2.0 value distribution.\n",
    "\n",
    "**To evaluate a predictive model (this is multi-class classifier) the following methods can be used:-**\n",
    "- Accuracy\n",
    "- Confusion Matrix\n",
    "- Precision (average is weighted because of multi-class)\n",
    "- Recall (average is weighted because of multi-class)\n",
    "- F1 score (average is weightedbecause of multi-class)\n",
    "- Classification Report\n",
    "- Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- Without using PCA, create a logistic regression model using practices discussed in class.  \n",
    "- Which model would you choose? Explain your results in the markdown cells.    \n",
    "- What is the accuracy, precision, and recall for the test data?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_std, y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predictions = lr.predict(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_training, y_train_predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723809671877416"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_training, y_train_predictions, average='weighted')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_training, y_train_predictions, average='weighted')\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.81      0.77       591\n",
      "         1.0       0.72      0.62      0.66       302\n",
      "         2.0       0.70      0.66      0.68       307\n",
      "\n",
      "    accuracy                           0.73      1200\n",
      "   macro avg       0.72      0.70      0.71      1200\n",
      "weighted avg       0.72      0.72      0.72      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_training, y_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predictions = lr.predict(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 2., 1., 0., 2., 2., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 2., 2., 2., 0., 2., 2., 0., 2., 1., 2., 2., 2., 2., 0., 2., 0.,\n",
       "       2., 2., 1., 1., 0., 2., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2.,\n",
       "       1., 1., 0., 2., 2., 1., 1., 2., 2., 1., 2., 0., 2., 0., 2., 0., 0.,\n",
       "       2., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 2., 1., 1., 0., 1., 0.,\n",
       "       2., 0., 0., 0., 2., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 2., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 2., 1., 0., 0., 1., 2., 1., 0., 0., 1., 2.,\n",
       "       0., 2., 2., 0., 0., 0., 1., 0., 0., 2., 2., 0., 2., 0., 0., 2., 2.,\n",
       "       0., 1., 0., 1., 0., 0., 2., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 2., 1., 2., 0., 1., 1., 1., 2., 2., 0., 2., 1., 2.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 2., 2., 2., 0., 0., 2., 0., 0., 0., 0.,\n",
       "       2., 2., 1., 2., 0., 0., 0., 1., 0., 0., 0., 2., 1., 2., 0., 2., 0.,\n",
       "       2., 1., 2., 0., 2., 0., 0., 0., 2., 0., 0., 0., 0., 0., 2., 0., 2.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 2.,\n",
       "       0., 0., 0., 1., 1., 0., 2., 1., 0., 0., 0., 2., 2., 1., 1., 1., 0.,\n",
       "       0., 2., 1., 0., 0., 2., 2., 1., 0., 0., 2., 2., 1., 0., 0., 0., 2.,\n",
       "       0., 2., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       2., 2., 1., 0., 0., 0., 0., 0., 2., 2., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033333333333334"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_test_predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7040254342431762"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_test_predictions, average='weighted')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7033333333333334"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_test_predictions, average='weighted')\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.76      0.76       153\n",
      "         1.0       0.68      0.59      0.63        74\n",
      "         2.0       0.62      0.68      0.65        73\n",
      "\n",
      "    accuracy                           0.70       300\n",
      "   macro avg       0.69      0.68      0.68       300\n",
      "weighted avg       0.70      0.70      0.70       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Describe results here\n",
    "\n",
    "**In the above cells, I have done the following:-**\n",
    "- Created logistic regression model.\n",
    "- Fit the model with the training data.\n",
    "- Get the predictions of training data.\n",
    "- Evaluate the model for training data\n",
    "    - Accuracy of training data is 72.5\n",
    "    - Precision score of training data is 72.3\n",
    "    - Recall score of training data is 72.5\n",
    "- Evalute the model for testing data\n",
    "    - Accuracy of testing data is 70.3\n",
    "    - Precision score of testing data is 70.4\n",
    "    - Recall score of testing data is 70.3\n",
    "\n",
    "**From the above results, I can say that this model has an accuarcy of 72 and 70 for training and testing data \n",
    "respectively which means it might be a good fit for this data not a best fit. This model is slightly overfitted.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- Use PCA within a pipeline to create a logistic regression model using best practices from class.  \n",
    "- Which model performs the best on the training data? Explain your results in markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?\n",
    "- Does this perform better than the original logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=10)),\n",
       "                (&#x27;model&#x27;, LogisticRegression(C=0.1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA(n_components=10)),\n",
       "                (&#x27;model&#x27;, LogisticRegression(C=0.1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=10)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()), ('pca', PCA(n_components=10)),\n",
       "                ('model', LogisticRegression(C=0.1))])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Pipeline([('scaling', StandardScaler()), \n",
    "              ('pca', PCA()),\n",
    "              ('model', LogisticRegression())\n",
    "             ])\n",
    "\n",
    "params = {'model__C': [0.01, 0.1, 1, 10], 'pca__n_components': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "\n",
    "df_search = GridSearchCV(p, param_grid=params, scoring='accuracy', cv=10, refit=True)\n",
    "df_search = df_search.fit(X_train, y_training)\n",
    "\n",
    "df_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 0., 2., 0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predictions = df_search.predict(X_train)\n",
    "y_train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_training, y_train_predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7233506696572418"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_training, y_train_predictions, average='weighted')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.725"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_training, y_train_predictions, average='weighted')\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.82      0.78       591\n",
      "         1.0       0.71      0.60      0.65       302\n",
      "         2.0       0.71      0.66      0.68       307\n",
      "\n",
      "    accuracy                           0.73      1200\n",
      "   macro avg       0.72      0.69      0.70      1200\n",
      "weighted avg       0.72      0.72      0.72      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_training, y_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 2., 1., 0., 2., 2., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 2., 2., 0., 0., 2., 2., 0., 0., 1., 2., 2., 2., 2., 0., 2., 0.,\n",
       "       0., 2., 1., 1., 0., 2., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 2.,\n",
       "       1., 1., 0., 2., 2., 1., 1., 2., 1., 1., 2., 0., 2., 0., 2., 0., 0.,\n",
       "       2., 0., 2., 0., 0., 1., 0., 0., 0., 1., 0., 2., 1., 1., 0., 1., 0.,\n",
       "       2., 0., 0., 0., 2., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 2., 0.,\n",
       "       2., 1., 0., 0., 1., 0., 2., 1., 0., 0., 1., 2., 1., 0., 0., 1., 2.,\n",
       "       0., 2., 2., 0., 0., 0., 2., 0., 0., 2., 2., 0., 2., 0., 0., 2., 2.,\n",
       "       0., 1., 0., 1., 0., 0., 2., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 2., 1., 0., 0., 1., 1., 1., 2., 2., 0., 2., 0., 2.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 2., 2., 2., 0., 0., 2., 0., 0., 0., 0.,\n",
       "       2., 2., 1., 2., 0., 0., 0., 0., 0., 0., 2., 2., 1., 2., 1., 2., 0.,\n",
       "       0., 1., 2., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 2., 0., 2.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 2.,\n",
       "       0., 0., 0., 1., 0., 0., 2., 1., 0., 0., 0., 2., 2., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 2., 2., 1., 0., 0., 2., 2., 1., 0., 0., 0., 2.,\n",
       "       0., 2., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       2., 2., 1., 0., 0., 0., 0., 0., 2., 2., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predictions = df_search.predict(X_test)\n",
    "y_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6866666666666666"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_test_predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6838285714285713"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_test_predictions, average='weighted')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6866666666666666"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_test_predictions, average='weighted')\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.77      0.75       153\n",
      "         1.0       0.63      0.54      0.58        74\n",
      "         2.0       0.64      0.66      0.65        73\n",
      "\n",
      "    accuracy                           0.69       300\n",
      "   macro avg       0.67      0.66      0.66       300\n",
      "weighted avg       0.68      0.69      0.68       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Describe your results here\n",
    "\n",
    "**In the above cells, I have done the following:-**\n",
    "- Created logistic regression model pipeline, also implemented PCA and also used GridSearchCV for model implementation.\n",
    "- Fit the model with the training data.\n",
    "- Get the predictions of training data.\n",
    "- Evaluate the model for training data\n",
    "    - Accuracy of training data is 72.5\n",
    "    - Precision score of training data is 72.3\n",
    "    - Recall score of training data is 72.5\n",
    "- Evalute the model for testing data\n",
    "    - Accuracy of testing data is 69\n",
    "    - Precision score of testing data is 68.3\n",
    "    - Recall score of testing data is 68.6\n",
    "\n",
    "**From the above results, I can say that this model has an accuarcy of 72 and 69 for training and testing data \n",
    "respectively which means it might be a good fit for this data not a best fit. This model is slightly overfitted.\n",
    "Original logistic regression model performs better than this model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Without using PCA, create a decision tree model using best practices discussed in class.  \n",
    "- Which model performs the best on the training data? Explain your results in the markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?  \n",
    "- Does this perform better than either of the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert code here\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_std, y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 2., 2., 0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predictions = dt.predict(X_train_std)\n",
    "y_train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_training, y_train_predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_training, y_train_predictions, average='weighted')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_training, y_train_predictions, average='weighted')\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       591\n",
      "         1.0       1.00      1.00      1.00       302\n",
      "         2.0       1.00      1.00      1.00       307\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_training, y_train_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1., 0., 0., 2., 2., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 2., 2., 0., 2., 1., 2., 0., 1., 1., 1., 2., 2., 1., 1., 2., 0.,\n",
       "       2., 1., 1., 1., 2., 2., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 2., 0., 2., 1., 0., 0., 1., 2., 0., 0., 1., 0., 0., 2.,\n",
       "       2., 2., 2., 0., 0., 1., 2., 2., 0., 1., 0., 2., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 2., 1., 2., 0., 1., 0., 2., 1., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       2., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 2., 2.,\n",
       "       0., 0., 2., 0., 0., 0., 2., 0., 0., 2., 2., 0., 0., 0., 0., 2., 2.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 2., 2., 0., 2.,\n",
       "       1., 0., 0., 0., 2., 1., 1., 0., 0., 2., 2., 2., 0., 2., 2., 0., 2.,\n",
       "       1., 2., 0., 0., 2., 0., 1., 1., 1., 2., 2., 0., 2., 2., 0., 0., 0.,\n",
       "       2., 0., 0., 2., 0., 2., 1., 1., 2., 2., 2., 1., 1., 1., 0., 2., 0.,\n",
       "       2., 1., 2., 0., 2., 0., 0., 1., 2., 1., 2., 0., 0., 1., 2., 2., 0.,\n",
       "       0., 0., 0., 0., 0., 2., 2., 0., 0., 0., 0., 0., 1., 0., 1., 1., 2.,\n",
       "       0., 0., 1., 1., 0., 0., 2., 1., 0., 0., 2., 1., 1., 2., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 2., 2., 1., 2., 0., 0., 2., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 2., 1., 1., 1., 1., 0., 0., 1., 1., 0., 2., 1., 0., 1., 0.,\n",
       "       0., 2., 1., 0., 1., 2., 0., 0., 0., 2., 0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predictions = dt.predict(X_test_std)\n",
    "y_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_test_predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735757575757575"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_test_predictions, average='weighted')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_test_predictions, average='weighted')\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.66      0.71       153\n",
      "         1.0       0.56      0.66      0.60        74\n",
      "         2.0       0.60      0.66      0.63        73\n",
      "\n",
      "    accuracy                           0.66       300\n",
      "   macro avg       0.64      0.66      0.65       300\n",
      "weighted avg       0.67      0.66      0.66       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Describe results here\n",
    "\n",
    "**In the above cells, I have done the following:-**\n",
    "- Created decision tree classifier model.\n",
    "- Fit the model with the training data.\n",
    "- Get the predictions of training data.\n",
    "- Evaluate the model for training data\n",
    "    - Accuracy of training data is 100\n",
    "    - Precision score of training data is 100\n",
    "    - Recall score of training data is 100\n",
    "- Evalute the model for testing data\n",
    "    - Accuracy of testing data is 66\n",
    "    - Precision score of testing data is 67\n",
    "    - Recall score of testing data is 66\n",
    "\n",
    "**From the above results, I can say that this model has an accuarcy of 100 and 66 for training and testing data \n",
    "respectively which means it is not a good fit for this data because it is overfitted (performs very well on training data and not on testing data).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "- Repeat `Question 5` but use PCA.  \n",
    "- Does this perform better than the original Decision Tree or the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 DecisionTreeClassifier(max_depth=10, min_samples_leaf=2,\n",
       "                                        min_samples_split=10))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaling&#x27;, StandardScaler()), (&#x27;pca&#x27;, PCA()),\n",
       "                (&#x27;model&#x27;,\n",
       "                 DecisionTreeClassifier(max_depth=10, min_samples_leaf=2,\n",
       "                                        min_samples_split=10))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=10)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()), ('pca', PCA()),\n",
       "                ('model',\n",
       "                 DecisionTreeClassifier(max_depth=10, min_samples_leaf=2,\n",
       "                                        min_samples_split=10))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code here\n",
    "p = Pipeline([('scaling', StandardScaler()), \n",
    "              ('pca', PCA()),\n",
    "              ('model', DecisionTreeClassifier())\n",
    "             ])\n",
    "\n",
    "param_grid = [\n",
    "  {'model__max_depth': [2, 5, 10],\n",
    "   'model__min_samples_split':[3, 5, 10],\n",
    "   'model__min_samples_leaf': [2, 5],\n",
    "   'model__class_weight':[None]\n",
    "  }\n",
    " ]\n",
    "\n",
    "dt_gcv_results = GridSearchCV(estimator=p, \n",
    "                           param_grid=param_grid, scoring='accuracy', refit=True)\n",
    "\n",
    "dt_gcv_results = dt_gcv_results.fit(X_train, y_training)\n",
    "dt_gcv_results.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., ..., 2., 2., 0.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_predictions = dt_gcv_results.predict(X_train)\n",
    "y_train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9116666666666666"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_training, y_train_predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9118742056980733"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_training, y_train_predictions, average='weighted')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9116666666666666"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_training, y_train_predictions, average='weighted')\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.97      0.94       591\n",
      "         1.0       0.91      0.84      0.87       302\n",
      "         2.0       0.92      0.87      0.90       307\n",
      "\n",
      "    accuracy                           0.91      1200\n",
      "   macro avg       0.91      0.89      0.90      1200\n",
      "weighted avg       0.91      0.91      0.91      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_training, y_train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 2., 1., 0., 0., 2., 2., 0., 0., 1., 1., 0., 1., 0., 1., 0., 2.,\n",
       "       0., 2., 2., 1., 2., 2., 2., 0., 1., 1., 2., 2., 2., 1., 0., 0., 0.,\n",
       "       2., 0., 1., 1., 0., 2., 0., 0., 2., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 2., 2., 2., 0., 0., 2., 2., 0., 0., 0., 0., 2., 0., 0.,\n",
       "       2., 0., 2., 0., 0., 0., 0., 0., 2., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 2., 1., 1., 0., 1., 0., 2., 1., 2., 1., 0., 0., 0., 2., 1.,\n",
       "       2., 0., 1., 0., 0., 0., 1., 1., 1., 1., 2., 2., 1., 0., 1., 1., 2.,\n",
       "       0., 1., 2., 1., 2., 0., 1., 0., 0., 2., 2., 0., 0., 0., 2., 2., 2.,\n",
       "       0., 0., 0., 1., 0., 2., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 2.,\n",
       "       0., 0., 0., 2., 0., 0., 0., 0., 0., 1., 1., 2., 0., 2., 0., 0., 2.,\n",
       "       1., 2., 0., 2., 0., 0., 1., 2., 1., 2., 2., 0., 0., 0., 0., 0., 1.,\n",
       "       2., 2., 2., 2., 0., 0., 1., 0., 1., 2., 2., 2., 1., 1., 0., 2., 0.,\n",
       "       2., 2., 2., 2., 2., 2., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 2., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 1., 1., 2., 0., 0., 0.,\n",
       "       0., 2., 0., 2., 0., 2., 2., 2., 0., 0., 0., 0., 1., 0., 0., 2., 2.,\n",
       "       0., 0., 2., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 2., 1., 0., 0., 2., 2., 0., 0., 2., 0.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_predictions = dt_gcv_results.predict(X_test)\n",
    "y_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7233333333333334"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_test_predictions)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.723493714565261"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = precision_score(y_test, y_test_predictions, average='weighted')\n",
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7233333333333334"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(y_test, y_test_predictions, average='weighted')\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.80      0.78       153\n",
      "         1.0       0.72      0.58      0.64        74\n",
      "         2.0       0.65      0.70      0.67        73\n",
      "\n",
      "    accuracy                           0.72       300\n",
      "   macro avg       0.71      0.69      0.70       300\n",
      "weighted avg       0.72      0.72      0.72       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Describe your results here\n",
    "\n",
    "**In the above cells, I have done the following:-**\n",
    "- Created decision tree classifier model pipeline, also implemented PCA and also used GridSearchCV for model implementation.\n",
    "- Fit the model with the training data.\n",
    "- Get the predictions of training data.\n",
    "- Evaluate the model for training data\n",
    "    - Accuracy of training data is 91\n",
    "    - Precision score of training data is 91\n",
    "    - Recall score of training data is 91\n",
    "- Evalute the model for testing data\n",
    "    - Accuracy of testing data is 72\n",
    "    - Precision score of testing data is 72\n",
    "    - Recall score of testing data is 72\n",
    "\n",
    "**From the above results, I can say that this model has an accuarcy of 91 and 73 for training and testing data \n",
    "respectively which means it might be a good fit for this data not a best fit. This model is overfitted.\n",
    "Original logistic regression model and logistic regression model using pca is slightly overfitted. But decision tree and decision tree using pca is more overfitted. I prefer logistic regression models from decision tree models because it is essentially required that the model should perform better on unseen data, when there is high rate of overfitting, it might not be possible to perform better on unseen data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
